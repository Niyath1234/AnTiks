#!/bin/bash
# Setup script for GGUF optimization on M4 Mac

echo "=========================================="
echo "Setting up GGUF Optimization for M4 Mac"
echo "=========================================="
echo ""

# Check if we're on macOS
if [[ "$OSTYPE" != "darwin"* ]]; then
    echo "‚ùå This script is for macOS only"
    exit 1
fi

echo "üì¶ Installing llama-cpp-python with Metal support..."
echo ""

# Install llama-cpp-python with Metal backend
CMAKE_ARGS="-DLLAMA_METAL=on" pip install llama-cpp-python --upgrade

echo ""
echo "‚úÖ Installation complete!"
echo ""
echo "üí° To verify installation, run:"
echo "   python -c 'from llama_cpp import Llama; print(\"‚úÖ llama-cpp-python installed\")'"
echo ""
echo "üöÄ Now you can use the optimized version:"
echo "   python test_interactive_optimized.py"


